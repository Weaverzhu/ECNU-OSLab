\subsection{Objectives}

\begin{itemize}
    \item 使 xv6 支持简单的 thread api
    \item 仿照 pthread 实现基本线程操作
    \item 实现两个系统调用 \texttt{int clone} 和 \texttt{int join}，\texttt{clone} 会指定一个函数，及其参数和新线程应有的 \texttt{stack} 空间，然后 \texttt{clone} 为其创建线程，将控制流指向函数，然后放入调度器。\texttt{join} 会等待一个子线程结束运行并且返回得到该线程的栈，用以回收资源
    \item 实现两个库函数 \texttt{thread\_create} 和 \texttt{thread\_join}，供用户使用
\end{itemize}

\subsection{Steps}

\begin{itemize}
    \item 我们实现的线程 \texttt{clone, join} 相当于进程中的 \texttt{fork, wait}。
    \item 线程有自己栈，但是共享内存空间和打开的设备和文件
    \item 创建线程和等待线程结束回收资源与 \texttt{fork, wait} 的区别主要在于需要对线程的栈进行操作
    \item 为线程栈分配空间的时候应该使用 \texttt{lock} 从而避免同时进入线程不安全的 \texttt{malloc}
\end{itemize}





\subsection{Concept: something about x86}

回顾一下 x86 一些寄存器的用途

\subsubsection{通用寄存器 (GPR)}

\noindent
\begin{tabularx}{\textwidth}{|X|X|X|X|X|X|X|X|X|}
    \hline
    Register & Accumu-lator & Base & Stack Pointer & Stack Base Pointer & Source & Desti-nation \\ \hline
    64-bit   & RAX          & RBX  & RSP           & RBP                & RSI    & RDI          \\ \hline
    32-bit   & EAX          & EBX  & ESP           & EBP                & ESI    & EDI          \\ \hline
    16-bit   & AX           & BX   & SP            & BP                 & SI     & DI           \\ \hline
\end{tabularx}

\subsubsection{指令寄存器 (IP)}

EIP 会指向下一个需要被执行的指令，如果没有分支的话。EIP 只有在 \texttt{call} 指令之后才会在堆栈上被读取

\subsection{Concept: CPU context}

回顾一下系统调用时上下文信息会存放在 trap frame 当中，在系统调用之后返回继续执行的时候会用这些信息重新组成上下文。所以我们如果要指定新的线程会进程（不管是在 \texttt{fork} 中还是 \texttt{clone} 中都需要设置 \texttt{proc->tf}）

CPU 进行上下文切换的时候只会保留需要保留的状态，实现的方法是保存堆栈指针（stack pointer), 并且使用一个新的。当一个函数被调用的时候，EIP 也就是指令寄存器会指向下一条指令被存放的位置。如果我们需要开始执行 \texttt{start\_routine} 的话，就要把它赋值为函数指针所指向的地址

\subsection{Concept: calling function}

x86 中 栈 (stack) 从地址高位开始向地位扩展，其中 ebp 在高位界限，esp 在低位界限。存入栈的机制是，从高到低移动 esp 并在新的 esp 位置开始放入数据

x86 执行一个函数的步骤如下：

在调用函数的地方：

\begin{enumerate}
    \item 反序将所有函数参数压入栈中
    \item 执行 \texttt{call} 指令，会把当前下一条指令压入栈中，然后修改 \texttt{eip} 的值，指向函数的第一条指令
\end{enumerate}

于是整个栈空间会变得像这样：

\begin{textcode}
    Parameter #N
    ...
    Parameter 2
    Parameter 1
    Return Address <--- (%esp)
\end{textcode}


在函数里面也有一些事情要做：

\begin{enumerate}
    \item 保存现在的 \texttt{ebp}，并将其赋值给 \texttt{esp}，这个过程相当于初始化一个栈空间给当前函数
\end{enumerate}

现在，ebp 往上是函数的参数，ebp往下就是函数自己的栈空间了

这个时候栈空间的样子：

\begin{textcode}
    Parameter #N <--- N*4+4(%ebp)
    ...
    Parameter 2 <--- 12(%ebp)
    Parameter 1 <--- 8(%ebp)
    Return Address <--- 4(%ebp)
    Old %ebp <--- (%esp) and (%ebp)
\end{textcode}

\begin{asmcode}
    subl $8, %esp
\end{asmcode}

之后函数将会给里面的本地变量预留出内存空间，方法就是扩大栈空间，将 \texttt{esp} 向低位移动。如果有两个参数的话那么栈空间是长成这个样子的:


\begin{textcode}
    Parameter #N <--- N*4+4(%ebp)
    ...
    Parameter 2 <--- 12(%ebp)
    Parameter 1 <--- 8(%ebp)
    Return Address <--- 4(%ebp)
    Old %ebp <--- (%ebp)
    Local Variable 1 <--- -4(%ebp)
    Local Variable 2 <--- -8(%ebp) and (%esp)
\end{textcode}

当函数返回的时候：

\begin{enumerate}
    \item 返回值存放在 \texttt{eax}
    \item 将栈回滚到调用这个函数的时候，也就是将 \texttt{ebp, esp} 重置为调用函数之前的值
    \item 使用 \texttt{ret} 指令将控制流送回，也就是将栈中存放的之前那个下一条指令的值放回 \texttt{eip}
\end{enumerate}

在 \texttt{clone} 中我们需要直接开始执行 \texttt{start\_routine} 函数，因此要由我们在 \texttt{clone} 系统调用中做好调用函数的工作

这里实现的要求是在新建的 thread 中压入 fake pc，也就是执行到 \texttt{exit} 位置，那么这样我们就需要在 \texttt{start\_routine} 中执行 \texttt{exit} 否则就会一直执行直到 \texttt{0xffffffff} 为止


\subsection{Concept: Thread \&  Process}

进程使操作系统虚拟化 CPU 的手段。在多程序同时运行的机器上，通过进程的实现使得每个程序都可以认为自己独占 CPU。

进程的信息被存放在 TCB (Thread Control Block) 中，而线程的信息被存放在 PCB 中 （Process Control Block)。但是，进程和线程有很类似的地方，他们都需要在调度器中被存储下关于上下文的东西，比如堆栈指针，一些寄存器的值，打开的文件（设备），上下文和运行状态等。

如果我们特意地去实现 TCB 和 PCB 并把它们区分开来，那么我们需要在 schedule 中耗费大量的精力。事实上进程和线程主要地区别在于派生出来的线程需要有额外自己的 stack frame，和父进程拥有相同的内存管理（page directory），有和父进程不一样的 pc。

所以这里我们用到的 trick 就是让 scheduler 认为进程和线程大抵是一样的东西（共用数据结构 \texttt{struct proc}）,修改结果加上线程自己的栈空间 \texttt{void *thread\_stack} 然后指定 \texttt{eip, esp} 来规定 \texttt{start\_routine} 和自己的栈空间

\subsection{Concept: Thread-safty}

函数的线程安全的含义差不多就是，多个线程同时执行这个函数（可能会包含共享资源）会不会发生错误。留意 \texttt{malloc, free} 当中会对 \texttt{freelist} 这一链表进行读写操作。如果我们什么都不做的话，显然不是线程安全的。我们直到对于一个共享链表，我们可以通过 \texttt{read-write lock}，对于每一个节点或者对整个链表加锁的方式使得多个线程能共享同一个链表。对整个链表加锁无疑是最方便的方法，虽然执行效率也是最低的（最 coarse-grained 的处理方式）

我们需要对 \texttt{malloc, free} 中的链表加一个锁，然后还需要找地方让这个锁初始化


\subsection{Code: clone \& join}

\subsubsection{system call}

回顾一下怎么增加一个系统调用，这是我们第一次作业已经做过的，这里不再详细赘述

主要流程就是:

\begin{itemize}
    \item 在 \texttt{./kernel/syscall.c, ./kernel/sysfunc.h, ./include/syscall.h} 中为我们两个新的 system call 添加新的定义
    \item 在 \texttt{./user/user.h} 中为用户空间添加定义
    \item 在 \texttt{./kernel/sysproc.c} 中为函数获取参数，并检查参数传递进来是合法的（使用\texttt{argptr} 等）
\end{itemize}


\subsubsection{clone}

\texttt{clone} 就是模仿 \texttt{fork} 制造一个假进程。相比 \texttt{fork} 中需要复制 \texttt{page table}，\texttt{clone} 需要将自己的页表指针指向同一个页表。

我们需要为 \texttt{clone} 指定一个新线程的栈。于是这里在构想的时候有两种方案：

\begin{itemize}
    \item 像上次 xv6 作业那样，在内核态中使用 \texttt{kvalloc} 手动分配分配空间
    \item 在用户态中使用 \texttt{malloc} 通过 \texttt{clone} 的参数传递
\end{itemize}

由于函数的原型已经给出了 \texttt{clone} 中确实包含 \texttt{stack} 这一参数，这里还是采用了第二种方法。而且对于第二种方法，还可以通过加锁的方式控制多个线程同时访问 \texttt{malloc} 或者 \texttt{thread\_join, thread\_create}

\begin{ccode}
    int i, pid;
    uint ustack[2];
    struct proc *np;
                    
    // check if stack is page-aligned
    if ((uint)stack % PGSIZE) return -1;
                    
    // Allocate process
    if ((np = allocproc()) == 0)
    return -1;
                    
    // share the address space
    np->pgdir = proc->pgdir;
                    
    // copy as in fork()
    np->sz = proc->sz;
    np->parent = proc;
    *np->tf = *proc->tf;
                    
    // fake pc
    ustack[0] = 0xffffffff;
                    
\end{ccode}

设置 \texttt{esp, ebp} 到指定的用户栈可以初始化线程的栈空间。之前介绍了 c 语言调用函数，参数压栈的方式。按照作业要求，\texttt{start\_routine}只有一个函数参数就是一个包含各种参数的指针 \texttt{arg}。这里返回地址压入的是 \texttt{0xffffffff} fake pc，也就是说一块非法内存地址。当 \texttt{start\_routine} 执行完毕之后会因为访问这个非法的返回地址而被中断 kill 掉，和 xv6 中所有没有执行 \texttt{exit} 的进程一样。所以按照道理来说我们期望用户能在 \texttt{start\_routine} 自行调用 \texttt{exit}，虽然作业要求中这一块没用明确说明。

\begin{ccode}
    // pass arg, args should be just above esp
    ustack[1] = (uint)arg;
    np->tf->esp = (uint)stack + PGSIZE- sizeof(ustack);
    // make user stack
    copyout(np->pgdir, np->tf->esp, ustack, sizeof(ustack));
    np->thread_stack = stack;
                  
    // start executing at the address specified by fcn
    np->tf->eip = (uint)fcn;
                  
    // clearing stack for fcn
    np->tf->ebp = np->tf->esp;
                  
    // Clear %eax so that fork returns 0 in the child.
    np->tf->eax = 0;
\end{ccode}

\texttt{file descriptor, proc->state} 等同样参照 \texttt{fork}

\begin{ccode}
    // file descriptors are copied as in fork
    for(i = 0; i < NOFILE; i++)
    if(proc->ofile[i])
    np->ofile[i] = filedup(proc->ofile[i]);
    np->cwd = idup(proc->cwd);
                   
    pid = np->pid;
    np->state = RUNNABLE;
    safestrcpy(np->name, proc->name, sizeof(proc->name));
    // cprintf("dbg: clone completed!, pid=%d, np->tf->eip=%p\n", pid, np->tf->eip);
    // procdump();
    return pid;
\end{ccode}

\subsubsection{wait \& join}

\texttt{join} 也要仿照 \texttt{wait}，遍历进程表中的每一个进程，找到对应的父子关系的子进程或者子线程。如果它是 \texttt{ZOMBIE} 状态，则回收栈空间资源。由于是用户空间传来的栈空间，这里我们需要将栈空间指针传回去

\texttt{wait, join} 是两个完全不同的行为，一个是等待子进程，一个是等待子线程。我们可以通过子进程线程的页表是否和父亲的相同判断它是一个线程还是一个进程

在 \texttt{wait} 当中我们需要添加

\begin{ccode}
    // we do not clear threads!!!
    if (p->pgdir == proc->pgdir)
    continue;
\end{ccode}

在 \texttt{join} 中我们也需要排除是子进程的情况

\begin{ccode}
    if (p->pgdir != proc->pgdir)
    continue;
\end{ccode}

剩下的和 \texttt{wait} 中大同小异，除了我们需要把线程栈传递给参数 \texttt{stack} 指针指向的指针

\begin{ccode}
                    
    int
    join(void **stack) {
        struct proc *p;
        int havekids, pid;
                                
        // stack should be in proc, which is allocated by malloc
        if ((proc->sz - (uint)stack) < sizeof(void**))
        return -1;
                                
        acquire(&ptable.lock);
        for(;;){
            // Scan through table looking for zombie children.
            // just like wait()
            havekids = 0;
            for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
                if(p->parent != proc)
                continue;
                if (p->pgdir != proc->pgdir)
                continue;
                havekids = 1;
                if(p->state == ZOMBIE){
                    // Found one.
                    pid = p->pid; cprintf("Found child thread, pid=%d\n", pid);
                    kfree(p->kstack);
                    p->kstack = 0;
                                                                                
                    // but not free the pgdir which is shared by parent process!
                    // freevm(p->pgdir);
                                                                                
                    p->state = UNUSED;
                    p->pid = 0;
                    p->parent = 0;
                    p->name[0] = 0;
                    p->killed = 0;
                    release(&ptable.lock);
                                                                                
                    // The location of the child's user stack is copied into the argument stack.
                    *stack = p->thread_stack;
                    return pid;
                }
            }
                                                
            // No point waiting if we don't have any children.
            if(!havekids || proc->killed){
                release(&ptable.lock);
                return -1;
            }
                                                
            sleep(proc, &ptable.lock);
        }
    }
\end{ccode}

和 \texttt{wait} 不一样，\texttt{join} 执行的时候地址空间一定会又父进程也就是调用 \texttt{join} 的进程还在引用，所以这里不能释放内存空间

\subsection{Code: exit}

\texttt{exit} 原来的功能除了将调用的进程的状态设置为 \texttt{ZOMBIE} 之外，还需要将要退出的子进程的父进程递交给 \texttt{initproc}。

对于要退出的子线程，直接关掉它（将他们也视为调用 \texttt{exit()})。虽然要求中没有对其有明确说明，发邮件询问助教也没有得到答复，但是这样设计的考量有如下：

\begin{itemize}
    \item 如果主进程调用 \texttt{exit()} 退出后状态为 \texttt{ZOMBIE}，它的内存空间随时可能会被它的父进程通过调用 \texttt{wait()} 回收掉，那么主进程的子线程将会莫名其妙的丢失自己的 \texttt{address space}
    \item 如果不 kill，那么子线程将没有任何可能回收它们共享的资源。进程可以重新归属于 \texttt{initproc}，但是线程不能，因为这些线程和 \texttt{initproc} 并不共享地址空间
\end{itemize}

\begin{ccode}
    acquire(&ptable.lock);
            
    // Parent might be sleeping in wait().s
    wakeup1(proc->parent);
            
    // Pass abandoned children to init.
    for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
        if(p->parent == proc){
            if (p->pgdir != proc->pgdir) {
                // transfer parent attr to initproc
                p->parent = initproc;
                if(p->state == ZOMBIE)
                wakeup1(initproc);
                } else {
                // kill all the threads!
                                                        
                p->state = ZOMBIE;
            }
        }
    }
            
    // Jump into the scheduler, never to return.
    proc->state = ZOMBIE;
    sched();
    panic("zombie exit");
\end{ccode}


\subsection{Code: thread\_create \& thread\_join}

我们需要使用 \texttt{malloc} 分配一个用户栈

\texttt{malloc} 当然不会返回 page aligned 的指针，所以我们需要多分配 4096 的空间来确保可以申请到一个 page aligned 的一个 page

然后我们调用 \texttt{clone}，并且分配一个 \texttt{malloc} 用作线程栈，传递函数指针

\begin{ccode}
    int
    thread_create(void (*start_routine)(void*), void *arg) 
    {
                  
        void *stack = malloc(4096 * 2);
        if (stack == NULL) return -1;
        stack = ((uint)stack + 4095) / 4096 * 4096;
        int pid = clone(start_routine, arg, stack);
        return pid;
    }
\end{ccode}

对于 \texttt{join}，我们回收之前扔进去的线程栈

\begin{ccode}
    int
    thread_join()
    {
        void *stack = malloc(sizeof(void*));
        int pid;
        if ((pid = join(&stack)) < 0) return -1;
        
        free(stack);
        
        return pid;
    }
\end{ccode}


\subsection{Code: add spinlock on malloc \& free}

还有一个关键的问题，就是多个线程同时改变自己的 \texttt{address space} 比如调用 \texttt{malloc, free} 等。\texttt{sbrk} 属于系统调用，内核态如果只有一个单元进入的话不会发生竞争情况，但是 \texttt{malloc, free} 读取的是一个在用户空间中的共享链表（见 \texttt{./user/umalloc.c}）。我们为每次读写链表都加锁

这里直接从上一次实验复制了一个自旋锁

\begin{ccode}
    typedef struct __lock_t { int flag; } lock_t;

    typedef volatile unsigned int spinlock_t;

    void spinlock_init(spinlock_t *lock);
    void spinlock_acquire(spinlock_t *lock);
    void spinlock_release(spinlock_t *lock);

    #define LOCK_ACQUIRED 1
    #define LOCK_FREE 0

    void spinlock_init(spinlock_t *lock)
    {
        printf(1, "init lock\n");
        *lock = LOCK_FREE;
    }

    void spinlock_acquire(spinlock_t *lock)
    {
        while (*lock || xchg(lock, LOCK_ACQUIRED))
        {
            asm("pause");
        }
    }

    void spinlock_release(spinlock_t *lock)
    {
        *lock = LOCK_FREE;
    }
\end{ccode}

在 \texttt{init} 程序中初始化锁

\begin{ccode}
    
    extern spinlock_t lock_freelist;

    int
    main(void)
    {
        int pid, wpid;
        // printf(1, "lock init\n");
        spinlock_init(&lock_freelist);
        // printf(1, "lock init completed\n");
        if(open("console", O_RDWR) < 0){
\end{ccode}

改变 \texttt{malloc, free} 使得一个地址空间只有一个线程可以访问，也就是禁止多个线程同时访问一个链表

\begin{ccode}
    
    void
    free(void *ap)
    {
        // spinlock_acquire(&lock_freelist);
        Header *bp, *p;

        bp = (Header*)ap - 1;
        for(p = freep; !(bp > p && bp < p->s.ptr); p = p->s.ptr)
            if(p >= p->s.ptr && (bp > p || bp < p->s.ptr))
            break;
        if(bp + bp->s.size == p->s.ptr){
            bp->s.size += p->s.ptr->s.size;
            bp->s.ptr = p->s.ptr->s.ptr;
        } else
            bp->s.ptr = p->s.ptr;
        if(p + p->s.size == bp){
            p->s.size += bp->s.size;
            p->s.ptr = bp->s.ptr;
        } else
            p->s.ptr = bp;
        freep = p;
        // spinlock_release(&lock_freelist);
    }
    void*
    malloc(uint nbytes)
    {
        in_malloc = 1;
        spinlock_acquire(&lock_freelist);
        Header *p, *prevp;
        uint nunits;

        nunits = (nbytes + sizeof(Header) - 1)/sizeof(Header) + 1;
        if((prevp = freep) == 0){
            base.s.ptr = freep = prevp = &base;
            base.s.size = 0;
        }
        for(p = prevp->s.ptr; ; prevp = p, p = p->s.ptr){
            if(p->s.size >= nunits){
            if(p->s.size == nunits)
                prevp->s.ptr = p->s.ptr;
            else {
                p->s.size -= nunits;
                p += p->s.size;
                p->s.size = nunits;
            }
            freep = prevp;
            spinlock_release(&lock_freelist);
            in_malloc = 0;
            return (void*)(p + 1);
            }
            if(p == freep)
            if((p = morecore(nunits)) == 0) {
                spinlock_release(&lock_freelist);
                in_malloc = 0;
                return 0;
            }
        }
    }

\end{ccode}

